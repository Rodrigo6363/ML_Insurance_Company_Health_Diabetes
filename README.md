# ü©∫ Diabetes Prediction Project (2017‚Äì2023)

This project explores and evaluates different machine learning models to predict the likelihood of diabetes in individuals, using health-related data from **2017 to 2023**. The goal is to build an accurate and interpretable pipeline that can be applied to real-world clinical screening contexts.

---

## üìÇ Project Structure

- **Data**: Preprocessed clinical and sociodemographic data.
- **Notebook**: Final pipeline including EDA, model training, evaluation, and comparison.
- **Figures**: All relevant visualizations and plots used for analysis and reporting.
- **Models**: Neural Network and best ML model saved for inference.
- **Utils**: Scripts used for visualizations and evaluations, used as a toolbox 
---

## üßº Data Preprocessing

The dataset includes both numerical and categorical features such as:
- Age, Weight, Height, Cholesterol levels, HbA1c, Blood pressure.
- Socio-demographics: Gender, Race, Country of birth, Income group.
- Feature engineering: BMI, CHOL ratio, Risk indices.

Steps:
- Missing value handling.
- Feature scaling with `StandardScaler`.
- Feature categorization (e.g., BMI categories, age groups).
- Train/test split.

---

## üìä Exploratory Data Analysis

### üéØ Target Distribution

![Target Distribution](src/img/target_distribution.png)

### üî¢ Numeric Features Distribution by Diabetes

![Numeric Distribution](src/img/bivariant.png)

### üßÆ Categorical Features Distribution by Target

![Categorical Distribution (Colored)](src/img/bivariant_cat.png)

### üî£ Raw Categorical Feature Frequencies

![Categorical Frequencies](src/img/cat_dist.png)

### üîó Correlation Matrix

![Correlation Matrix](src/img/correlation_matrix.png)

---

## ü§ñ Model Training & Evaluation

### üß† Neural Network (Keras)

A feedforward neural network with:
- Dense layers + BatchNormalization + Dropout.
- Loss: Binary Crossentropy.
- Metrics: Accuracy, AUC, Precision, Recall.

> Achieved high **recall (0.89)** but with lower **precision (0.40)**.

![Confusion Matrix NN](src/img/matrix_nn_pred.png)

---

### üì¶ Machine Learning Models

Multiple models were trained and evaluated using cross-validation, including:
- Logistic Regression, Random Forest, XGBoost, LightGBM, CatBoost, etc.

### üìà Model Comparison (by Mean Recall)

![Model Comparison](src/img/recall.png)

### ‚úÖ Best Performing Model: Gradient Boosting

- Best trade-off between accuracy, precision, and recall.
- Final evaluation:

![Confusion Matrix ML](src/img/matrix_ml_pred.png)

---

## üìå Conclusions

- The **neural network** achieved **very high sensitivity**, ideal for screening use cases where missing a positive case is costly.
- The **machine learning models** (particularly Gradient Boosting and LightGBM) offered **more balanced performance**, with better precision and F1-score.
- Depending on the clinical goal (screening vs diagnosis), either model can be deployed.

---
## üìÅ Files Included
- `data/`
  - `Prep_data/`: All the data to predict, clean and structured by categories.
  - `raw_data/`: All data scraped directly from the web, divided by categories.
  - `Train_data/`: All the data to train, clean and structured by categories.
  - `data_sample.csv`: Sample to show the general structure of the data.
- `img/`: All graphs and visualizations used.
- `models/`
  - `diabetes_nn_model.h5`: Trained Keras model.
  - `best_lightgbm_model.pkl`: Best trained ML model.
-`notebooks`: All notebooks used in the analisys and prediction of this data.
- `result_notebook/`
  - `Final_notebook.ipynb`: Final model pipeline, from preprocessing to evaluation.
- `utils`: Scripts used for visualizations and evaluations, used as a toolbox
- `requirements.txt`: List of packages used during the project


# Proyecto de Predicci√≥n de Diabetes (2017‚Äì2023)

Este proyecto explora y eval√∫a distintos modelos de aprendizaje autom√°tico para predecir la probabilidad de padecer diabetes, utilizando datos de salud recopilados entre **2017 y 2023**. El objetivo es construir una pipeline precisa e interpretable que pueda aplicarse en contextos cl√≠nicos reales de cribado.

---

## üìÇ Estructura del Proyecto

- **Data**: Datos cl√≠nicos y sociodemogr√°ficos preprocesados.
- **Notebook**: Pipeline final con an√°lisis exploratorio, entrenamiento, evaluaci√≥n y comparaci√≥n de modelos.
- **Figures**: Todas las visualizaciones y gr√°ficos utilizados en el an√°lisis y los informes.
- **Models**: Red neuronal y mejor modelo ML guardados para inferencia.
- **Utils**: Scripts usados para visualizaci√≥n y evaluaci√≥n, organizados como una toolbox.
---

## üßº Preprocesamiento de Datos

El conjunto de datos incluye variables num√©ricas y categ√≥ricas como:
- Edad, peso, altura, niveles de colesterol, HbA1c, presi√≥n arterial.
- Sociodemogr√°ficos: g√©nero, raza, pa√≠s de nacimiento, grupo de ingresos.
- Ingenier√≠a de variables: IMC, ratio de colesterol, √≠ndices de riesgo.

Pasos:
- Tratamiento de valores faltantes.
- Escalado de caracter√≠sticas con `StandardScaler`.
- Categorizaci√≥n de variables (e.g., categor√≠as de IMC, grupos de edad).
- Divisi√≥n train/test.

---

## üìä An√°lisis Exploratorio de Datos

### üéØ Distribuci√≥n del Target

![Distribuci√≥n del Target](src/img/target_distribution.png)

### üî¢ Distribuci√≥n de Variables Num√©ricas seg√∫n Diabetes

![Distribuci√≥n Num√©rica](src/img/bivariant.png)

### üßÆ Distribuci√≥n de Variables Categ√≥ricas seg√∫n Target

![Distribuci√≥n Categ√≥rica](src/img/bivariant_cat.png)

### üî£ Frecuencia de Variables Categ√≥ricas (sin procesar)

![Frecuencia Categ√≥rica](src/img/cat_dist.png)

### üîó Matriz de Correlaci√≥n

![Matriz de Correlaci√≥n](src/img/correlation_matrix.png)

---

## ü§ñ Entrenamiento y Evaluaci√≥n de Modelos

### üß† Red Neuronal (Keras)

Red neuronal densa con:
- Capas `Dense` + `BatchNormalization` + `Dropout`.
- Funci√≥n de p√©rdida: Binary Crossentropy.
- M√©tricas: Accuracy, AUC, Precision, Recall.

> Se alcanz√≥ un **recall alto (0.89)** pero una **precisi√≥n baja (0.40)**.

![Matriz de Confusi√≥n NN](src/img/matrix_nn_pred.png)

---

### üì¶ Modelos de Aprendizaje Autom√°tico

Se entrenaron y evaluaron varios modelos con validaci√≥n cruzada, incluyendo:
- Regresi√≥n log√≠stica, Random Forest, XGBoost, LightGBM, CatBoost, etc.

### üìà Comparaci√≥n de Modelos (por Recall medio)

![Comparaci√≥n de Modelos](src/img/recall.png)

### ‚úÖ Modelo con Mejor Desempe√±o: Gradient Boosting

- Mejor equilibrio entre precisi√≥n, recall y exactitud.
- Evaluaci√≥n final:

![Matriz de Confusi√≥n ML](src/img/matrix_ml_pred.png)

---

## üìå Conclusiones

- La **red neuronal** logr√≥ **muy alta sensibilidad**, ideal para escenarios de cribado donde es crucial no omitir casos positivos.
- Los **modelos de ML** (especialmente Gradient Boosting y LightGBM) ofrecieron un rendimiento m√°s equilibrado, con mejor precisi√≥n y F1-score.
- Dependiendo del objetivo cl√≠nico (cribado vs diagn√≥stico), se puede optar por uno u otro modelo.

---

## üìÅ Archivos Incluidos

- `data/`
  - `Prep_data/`: Todos los datos para la predicci√≥n, limpios y estructurados por categor√≠a.
  - `raw_data/`: Datos sin procesar descargados desde la web, por categor√≠a.
  - `Train_data/`: Datos para entrenamiento, limpios y estructurados.
  - `data_sample.csv`: Muestra representativa de la estructura de los datos.
- `img/`: Todas las gr√°ficas y visualizaciones utilizadas.
- `models/`
  - `diabetes_nn_model.h5`: Modelo Keras entrenado.
  - `best_lightgbm_model.pkl`: Mejor modelo de ML entrenado.
- `notebooks`: Notebooks usados en el an√°lisis y predicci√≥n.
- `result_notebook/`
  - `Final_notebook.ipynb`: Pipeline final, desde el preprocesamiento hasta la evaluaci√≥n.
- `utils`: Scripts de evaluaci√≥n y visualizaci√≥n usados como toolbox.
- `requirements.txt`: Lista de paquetes usados en el proyecto.
